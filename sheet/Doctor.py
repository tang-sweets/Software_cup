import os
import torch
from PIL import Image
from torchvision import transforms
from torchvision.models import resnet18
import requests
import json
import streamlit as st
import threading
import sounddevice as sd
import wavio
from tools.chat_histor import save_data, load_data, get_history_chats, remove_data
import re

def strip_sup_tags(text):
    return re.sub(r'<sup>\d+</sup>', '', text)

# è®¾ç½® API Key
API_KEY = st.secrets["api"]["bianxie_key"]
YI_API_KEY = st.secrets["api"]["Yi_key"]

# å›¾åƒåˆ†ç±»å‡½æ•°
def classify_image(class_names, image):
    num_classes = len(class_names)
    model = resnet18(pretrained=True)
    num_ftrs = model.fc.in_features
    model.fc = torch.nn.Linear(num_ftrs, num_classes)
    model.eval()

    # åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹æƒé‡
    checkpoint_path = './static/models/doctor.pth'
    if os.path.exists(checkpoint_path):
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        model.load_state_dict(checkpoint)
    else:
        st.error("é¢„è®­ç»ƒæ¨¡å‹æƒé‡æ–‡ä»¶æœªæ‰¾åˆ°ã€‚")

    # å›¾åƒé¢„å¤„ç†
    data_transform = transforms.Compose([
        transforms.Resize((224, 224)),  # å°†å›¾åƒè°ƒæ•´ä¸ºæ¨¡å‹æ‰€éœ€çš„å¤§å°
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    image = Image.open(image).convert("RGB")  # å°†å›¾åƒè½¬æ¢ä¸ºRGBæ ¼å¼
    image = data_transform(image).unsqueeze(0)
    image = image.to('cpu')  # å°†å›¾åƒæ”¾åˆ°CPUä¸Š

    # åœ¨æ¨¡å‹ä¸Šè¿›è¡Œé¢„æµ‹
    with torch.no_grad():
        outputs = model(image)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        _, predicted = torch.max(outputs.data, 1)

    probabilities_dict = {class_names[i]: probabilities.tolist()[0][i] for i in range(num_classes)}

    result = {
        "class_index": predicted.item(),
        "class_name": class_names[predicted.item()],
        "probabilities": probabilities_dict
    }

    return result

# è¯­éŸ³å½•åˆ¶å’Œè½¬å½•å‡½æ•°
def record_audio(file_path, duration=30, fs=44100):
    """å½•éŸ³å‡½æ•°ï¼Œå°†å½•éŸ³ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶è·¯å¾„"""
    recording = sd.rec(int(duration * fs), samplerate=fs, channels=2)
    sd.wait()  # ç­‰å¾…å½•éŸ³ç»“æŸ
    wavio.write(file_path, recording, fs, sampwidth=2)

def transcribe_audio(file_path):
    """è¯­éŸ³è¯†åˆ«å‡½æ•°ï¼Œå°†éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ å¹¶è¿”å›è¯†åˆ«æ–‡æœ¬"""
    url = 'https://api.bianxieai.com/v1/audio/transcriptions'
    headers = {
        "Authorization": f"Bearer {API_KEY}"
    }
    files = {
        "file": ("audio.wav", open(file_path, "rb")),
        "model": (None, "whisper-1")
    }

    response = requests.post(url, headers=headers, files=files)

    if response.status_code == 200:
        return response.json().get('text', '')
    else:
        raise Exception(f"Failed to get translation: {response.status_code} - {response.text}")

def yi_stream_response(api_key, model, message_history, username):
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    data = {"model": model, "messages": message_history, "temperature": st.session_state.get("temperature", 0.9), "top_p": st.session_state.get("top_p", 0.3), "stream": True}
    response = requests.post(f"https://api.lingyiwanwu.com/v1/chat/completions", headers=headers, json=data, stream=True)

    if response.status_code == 200:
        assistant_response = st.empty()
        assistant_content = ""

        for chunk in response.iter_lines(decode_unicode=False):
            if chunk:
                chunk = chunk.decode('utf-8')
                if chunk.startswith("data: "):
                    chunk_data = chunk[len("data: "):].strip()
                    if chunk_data == "[DONE]":
                        break
                    try:
                        chunk_json = json.loads(chunk_data)
                        chunk_message = chunk_json['choices'][0]['delta']
                        if 'content' in chunk_message and chunk_message['content']:
                            assistant_content += chunk_message['content']
                            # Remove <sup> tags
                            cleaned_content = strip_sup_tags(assistant_content)
                            assistant_response.markdown(cleaned_content)
                    except json.JSONDecodeError as e:
                        st.error(f"JSONDecodeError: {e}")
                        continue
        if assistant_content.strip():
            st.session_state["messages"].append({"role": "assistant", "content": strip_sup_tags(assistant_content)})
            if st.session_state["chat_name"]:
                save_data(username, st.session_state["chat_name"], message_history)
            st.experimental_rerun()
    else:
        st.error(f"Error: {response.status_code}, {response.text}")


def handle_audio_input(api_key, message_history, username):
    """å¤„ç†éŸ³é¢‘è¾“å…¥å¹¶æ‰§è¡Œç›¸åº”æ“ä½œ"""
    if 'is_recording' not in st.session_state:
        st.session_state['is_recording'] = False

    if st.button("ğŸ™ï¸è¯­éŸ³è¾“å…¥", key="audio_input"):
        if not st.session_state['is_recording']:
            st.session_state['is_recording'] = True
            st.info("è†å¬ä¸­ã€‚ã€‚ã€‚å†æ¬¡å•å‡»è¯¥æŒ‰é’®å¯åœæ­¢ã€‚")
            threading.Thread(target=record_audio, args=("static/wav/temp.wav", 30)).start()
        else:
            st.session_state['is_recording'] = False
            st.info("è¯­éŸ³è¾“å…¥å®Œæˆã€‚å•å‡»â€œğŸ“â€å¼€å§‹è½¬å½•ã€‚")
            os.system("taskkill /im audiod.exe /f")

    if st.button("ğŸ“è½¬å½•è¯­éŸ³", key="transcribe_audio"):
        st.info("æ­£åœ¨è½¬å½•ï¼Œè¯·ç¨å€™...")
        try:
            transcription = transcribe_audio("static/wav/temp.wav")
            st.success("è½¬å½•å®Œæˆ")
            st.chat_message("user").write(transcription)
            message_history.append({"role": "user", "content": transcription})
            yi_stream_response(api_key, "yi-large-rag", message_history, username)
            save_data(username, st.session_state["chat_name"], message_history)
            st.experimental_rerun()
        except Exception as e:
            st.error(e)
            st.write(f"è½¬å½•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

def reset_classification_state():
    """é‡ç½®åˆ†ç±»ç›¸å…³çŠ¶æ€"""
    st.session_state["image_classified"] = False
    st.session_state["classification_result"] = None
    st.session_state["uploaded_file"] = None

# å¤„ç†ä¸åŒçš„ä»»åŠ¡
def handle_ai_task(prompt, task_type, messages, stream=True):
    api_key = st.secrets["api"]["Yi_key"]
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}

    task_prompts = {
        "çš®è‚¤ç—…è¯†åˆ«ä¸æ²»ç–—": "è¯·æ ¹æ®ä¸Šä¼ çš„çš®è‚¤ç—…å›¾ç‰‡ï¼Œè¯†åˆ«å‡ºçš®è‚¤ç—…çš„ç±»å‹ï¼Œå¹¶æä¾›è¯¦ç»†çš„ç—‡çŠ¶æè¿°å’Œæ²»ç–—æ–¹æ³•ã€‚",
        "æ¨èå°±è¯Šç§‘å®¤": "æ ¹æ®ç”¨æˆ·æè¿°çš„ç—‡çŠ¶ï¼Œæ¨èé€‚åˆå°±è¯Šçš„ç§‘å®¤ã€‚",
        "ç–¾ç—…æ¨æ–­": "æ ¹æ®ç”¨æˆ·æè¿°çš„ç—‡çŠ¶ï¼Œæ¨æ–­å¯èƒ½çš„ç–¾ç—…ã€‚å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·ç»§ç»­è¯¢é—®ç”¨æˆ·ä»¥è·å–æ›´å¤šä¿¡æ¯ï¼Œç›´åˆ°èƒ½å¤Ÿåšå‡ºåˆç†çš„æ¨æ–­ã€‚",
    }

    data = {
        "model": "yi-large-rag",
        "messages": messages + [{"role": "user", "content": f"{task_prompts[task_type]} {prompt}"}],
        "temperature": 0.9,
        "top_p": 0.3,
        "stream": stream,
        "max_tokens": 4096  # è®¾ç½®æœ€å¤§è¾“å‡ºé•¿åº¦ä¸º4096
    }

    response = requests.post("https://api.lingyiwanwu.com/v1/chat/completions", headers=headers, json=data, stream=stream)

    if response.status_code == 200:
        if stream:
            assistant_content = ""
            assistant_response = st.empty()
            for chunk in response.iter_lines(decode_unicode=False):
                if chunk:
                    chunk = chunk.decode('utf-8')
                    if chunk.startswith("data: "):
                        chunk_data = chunk[len("data: "):].strip()
                        if chunk_data == "[DONE]":
                            break
                        try:
                            chunk_json = json.loads(chunk_data)
                            chunk_message = chunk_json['choices'][0]['delta']
                            if 'content' in chunk_message and chunk_message['content']:
                                assistant_content += chunk_message['content']
                                assistant_response.markdown(assistant_content)
                        except json.JSONDecodeError as e:
                            st.error(f"JSONDecodeError: {e}")
                            continue
            return assistant_content
        else:
            return response.json()['choices'][0]['message']['content']
    else:
        st.error(f"Error: {response.status_code}, {response.text}")
        return None

def main(__login__obj):
    """ä¸»å‡½æ•°ï¼Œåˆå§‹åŒ–åº”ç”¨ç¨‹åºå¹¶å¤„ç†ç”¨æˆ·äº¤äº’"""
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "chat_name" not in st.session_state:
        st.session_state["chat_name"] = None
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    if "image_classified" not in st.session_state:
        st.session_state["image_classified"] = False
    if "classification_result" not in st.session_state:
        st.session_state["classification_result"] = None
    if "uploaded_file" not in st.session_state:
        st.session_state["uploaded_file"] = None

    # è·å–ç”¨æˆ·å
    username = __login__obj.get_username()

    st.title('å¥åº·åŠ©æ‰‹')

    st.sidebar.title("é€‰æ‹©åŠŸèƒ½")
    function_option = ["çš®è‚¤ç—…è¯†åˆ«ä¸æ²»ç–—", "æ¨èå°±è¯Šç§‘å®¤", "ç–¾ç—…æ¨æ–­"]
    chosen_function = st.sidebar.selectbox("åŠŸèƒ½", function_option)

    # ä¾§è¾¹æ è¾“å…¥ API å¯†é’¥å’Œè®¾ç½®
    with st.sidebar:
        st.write("é€‰æ‹©æ¨¡å‹:")
        st.session_state["current_model_Yi"] = "yi-large-rag"

        existing_chats = get_history_chats(username)
        selected_chat = st.selectbox("é€‰æ‹©èŠå¤©è®°å½•", [""] + existing_chats)

        if selected_chat and selected_chat != st.session_state.get("chat_name"):
            st.session_state["chat_name"] = selected_chat
            st.session_state["messages"] = load_data(username, selected_chat)
            reset_classification_state()
            st.experimental_rerun()

        new_chat_name = st.text_input("æ–°å»ºèŠå¤©åç§°", "")

        cols = st.columns(3)
        with cols[0]:
            if st.button("æ–°å»ºèŠå¤©"):
                if not new_chat_name:
                    new_chat_name = f"chat_{len(existing_chats) + 1}"
                st.session_state["chat_name"] = new_chat_name
                st.session_state["messages"] = []
                save_data(username, new_chat_name, st.session_state["messages"])
                reset_classification_state()
                st.experimental_rerun()

        with cols[1]:
            if st.button("åˆ é™¤èŠå¤©") and selected_chat:
                remove_data(username, selected_chat)
                reset_classification_state()
                st.experimental_rerun()

    if st.session_state["last_chosen_function"] != chosen_function:
        st.session_state["messages"] = []
        st.session_state["last_chosen_function"] = chosen_function

    # åœ¨åŠŸèƒ½â€œçš®è‚¤ç—…è¯†åˆ«ä¸æ²»ç–—â€ä¸­æ›´æ–°è¯¦ç»†æç¤º
    if chosen_function == "çš®è‚¤ç—…è¯†åˆ«ä¸æ²»ç–—":
        uploaded_file = st.file_uploader("ä¸Šä¼ çš®è‚¤ç—…å›¾ç‰‡", type=["jpg", "jpeg", "png"])
        if uploaded_file is not None:
            if uploaded_file != st.session_state["uploaded_file"]:
                reset_classification_state()
                st.session_state["uploaded_file"] = uploaded_file

            class_names = ['å…‰åŒ–æ€§è§’åŒ–ç—…', 'åŸºåº•ç»†èƒç™Œ', 'çš®è‚¤çº¤ç»´ç˜¤', 'é»‘è‰²ç´ ç˜¤', 'ç—£', 'è‰²ç´ æ€§è‰¯æ€§è§’åŒ–ç—…',
                           'è„‚æº¢æ€§è§’åŒ–ç—…', 'é³çŠ¶ç»†èƒç™Œ', 'è¡€ç®¡ç—…å˜']  # ç¤ºä¾‹ä¸­æ–‡ç±»åˆ«åç§°
            st.image(uploaded_file, caption="ä¸Šä¼ çš„çš®è‚¤ç—…å›¾ç‰‡", use_column_width=True)
            if not st.session_state["image_classified"]:
                with st.spinner("è¯†åˆ«ä¸­..."):
                    result = classify_image(class_names, uploaded_file)
                    st.session_state["classification_result"] = result
                    st.session_state["image_classified"] = True

                    diagnosis_message = f"""
    åˆ†ç±»ç»“æœ: {result['class_name']}ã€‚
    è¯·æä¾›è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    - è¿™ç§çš®è‚¤ç—…çš„å¸¸è§ç—‡çŠ¶
    - å¯èƒ½çš„è‡´ç—…åŸå› 
    - å¸¸è§çš„æ²»ç–—æ–¹æ³•
    - æ—¥å¸¸æŠ¤ç†å»ºè®®
    """
                    st.session_state["messages"].append({"role": "user", "content": diagnosis_message})
                    st.chat_message("user").write(diagnosis_message)
                    yi_stream_response(YI_API_KEY, "yi-large-rag", st.session_state["messages"], username)

        if st.session_state["classification_result"] is not None:
            result = st.session_state["classification_result"]
            st.write(f"åˆ†ç±»ç»“æœ: {result['class_name']}")
            st.write("æ¦‚ç‡åˆ†å¸ƒ:")
            st.json(result["probabilities"])

    # åœ¨åŠŸèƒ½â€œæ¨èå°±è¯Šç§‘å®¤â€ä¸­æ›´æ–°è¯¦ç»†æç¤º
    elif chosen_function == "æ¨èå°±è¯Šç§‘å®¤":
        symptoms = st.text_area("è¯·è¾“å…¥æ‚¨çš„ç—‡çŠ¶æè¿°", "è¯¦ç»†æè¿°æ‚¨çš„ç—‡çŠ¶...")
        if st.button("æ¨èç§‘å®¤"):
            if symptoms.strip():
                prompt = f"""
    ç”¨æˆ·æè¿°çš„ç—‡çŠ¶æ˜¯ï¼š{symptoms}ã€‚
    è¯·æ ¹æ®è¿™äº›ç—‡çŠ¶æ¨èç”¨æˆ·åº”è¯¥å»çš„å°±è¯Šç§‘å®¤ã€‚è¯·æä¾›ï¼š
    - ä¸€ä¸ªæˆ–å¤šä¸ªå…·ä½“çš„ç§‘å®¤åç§°ï¼ˆä¾‹å¦‚ï¼Œçš®è‚¤ç§‘ï¼Œå†…ç§‘ï¼Œè€³é¼»å–‰ç§‘ç­‰ï¼‰
    - è¿™äº›ç§‘å®¤çš„èŒè´£èŒƒå›´
    - ä¸ºä»€ä¹ˆè¿™äº›ç§‘å®¤é€‚åˆç”¨æˆ·çš„ç—‡çŠ¶
    - å¦‚æœç—‡çŠ¶æ¶‰åŠå¤šä¸ªç§‘å®¤ï¼Œè¯·æ˜ç¡®ä¼˜å…ˆçº§æˆ–æ¨èé¡ºåº
    """
                st.session_state["messages"].append({"role": "user", "content": prompt})
                st.chat_message("user").write(prompt)
                yi_stream_response(YI_API_KEY, "yi-large-rag", st.session_state["messages"], username)
                save_data(username, st.session_state["chat_name"], st.session_state["messages"])

    # åœ¨åŠŸèƒ½â€œç–¾ç—…æ¨æ–­â€ä¸­æ›´æ–°è¯¦ç»†æç¤º
    elif chosen_function == "ç–¾ç—…æ¨æ–­":
        symptoms = st.text_area("è¯·è¾“å…¥æ‚¨çš„ç—‡çŠ¶æè¿°", "è¯¦ç»†æè¿°æ‚¨çš„ç—‡çŠ¶...")
        if st.button("æ¨æ–­ç–¾ç—…"):
            if symptoms.strip():
                prompt = f"""
    ç”¨æˆ·æè¿°çš„ç—‡çŠ¶æ˜¯ï¼š{symptoms}ã€‚
    è¯·æ ¹æ®è¿™äº›ç—‡çŠ¶æ¨æ–­ç”¨æˆ·å¯èƒ½æ‚£çš„ç–¾ç—…ã€‚
    - åˆ—å‡ºä¸€ä¸ªæˆ–å¤šä¸ªå¯èƒ½çš„ç–¾ç—…
    - å¯¹æ¯ä¸ªç–¾ç—…è¿›è¡Œè¯¦ç»†è§£é‡Šï¼ŒåŒ…æ‹¬å…¶ä¸»è¦ç—‡çŠ¶ã€åŸå› å’Œå¯èƒ½çš„æ²»ç–—æ–¹æ³•
    - å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·ç»§ç»­è¯¢é—®ç”¨æˆ·ä»¥è·å–æ›´å¤šä¿¡æ¯ï¼Œç›´åˆ°èƒ½å¤Ÿåšå‡ºåˆç†çš„æ¨æ–­ã€‚
    """
                st.session_state["messages"].append({"role": "user", "content": prompt})
                st.chat_message("user").write(prompt)
                yi_stream_response(YI_API_KEY, "yi-large-rag", st.session_state["messages"], username)
                save_data(username, st.session_state["chat_name"], st.session_state["messages"])

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for msg in st.session_state["messages"]:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯ï¼š"):
        if prompt.strip():  # ç¡®ä¿è¾“å…¥å†…å®¹éç©º
            st.session_state["messages"].append({"role": "user", "content": prompt})
            st.chat_message("user").write(prompt)
            yi_stream_response(YI_API_KEY, "yi-large-rag", st.session_state["messages"], username)
            save_data(username, st.session_state["chat_name"], st.session_state["messages"])

    handle_audio_input(YI_API_KEY, st.session_state["messages"], username)

if __name__ == "__main__":
    main(__login__obj)

